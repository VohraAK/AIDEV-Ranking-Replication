{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db7c1749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import langchain\n",
    "import os\n",
    "import time\n",
    "\n",
    "from langchain.chat_models import ChatOllama\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "from prompts import system_prompt, user_prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ab05953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "number",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "body",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "agent",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "986906c5-16fc-4f68-bbbd-699be5ab5913",
       "rows": [
        [
         "0",
         "7854",
         "perf",
         "Improve Rust compiler output",
         "## Summary\n- tweak Rust compiler to print simple string literals without format placeholders\n- regenerate machine Rust sources\n\n## Testing\n- `go test -tags slow -run TestCompilePrograms -count=1`\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_68715b38854c8320855125435fd36480",
         "OpenAI_Codex"
        ],
        [
         "1",
         "856",
         "perf",
         "perf(web): use route matcher in edge middleware",
         "Use Next.js `matcher` in edge middleware to optimize API route handling.",
         "Cursor"
        ],
        [
         "2",
         "2463",
         "perf",
         "Improve Java compiler runtime emission",
         "## Summary\n- only emit Java runtime helpers when they are actually required\n\n## Testing\n- `go test ./... --vet=off`\n\n------\nhttps://chatgpt.com/codex/tasks/task_e_68562cdb3f908320af3140f85aad43f3",
         "OpenAI_Codex"
        ],
        [
         "3",
         "70",
         "perf",
         "Improve TTI provider reliability",
         "## Summary\n- verify proxies when fetching from ProxyFox\n- retry requests with new proxies on failure\n\n## Testing\n- `ruff check webscout/Provider/TTI/utils.py webscout/Provider/OPENAI/autoproxy.py`\n- `pytest -q` *(fails: ModuleNotFoundError: No module named 'cloudscraper')*\n\n------\nhttps://chatgpt.com/codex/tasks/task_b_683d2b735bb083278874be4819ce945d",
         "OpenAI_Codex"
        ],
        [
         "4",
         "12025",
         "perf",
         "Add fast-paths for ToolLocationHelper property functions",
         "This PR adds fast-path implementations for two commonly used ToolLocationHelper property functions that were identified as performance bottlenecks in template projects:\n\n- `GetPlatformSDKLocation(String, String)`\n- `GetPlatformSDKDisplayName(String, String)`\n\n## Problem\nWhen building template projects in .NET 10.0.100-preview.5, these property functions don't have fast paths and require expensive reflection calls during project evaluation. The tracing output showed:\n\n```\nReceiverType=Microsoft.Build.Utilities.ToolLocationHelper; ObjectInstanceType=; MethodName=GetPlatformSDKLocation(String, String)\nReceiverType=Microsoft.Build.Utilities.ToolLocationHelper; ObjectInstanceType=; MethodName=GetPlatformSDKDisplayName(String, String)\n```\n\n## Solution\nAdded fast-path implementations in `WellKnownFunctions.cs` following the established pattern:\n\n1. **Added project reference** to `Microsoft.Build.Utilities.csproj` in the Build project to access ToolLocationHelper\n2. **Implemented fast-paths** for both methods with proper argument validation using `ParseArgs.TryGetArgs`\n3. **Added test coverage** to verify the implementation works correctly\n\nThe fast-paths avoid the expensive reflection mechanism and provide direct calls to the underlying methods when the signature matches exactly (two string parameters).\n\n## Changes\n- `src/Build/Microsoft.Build.csproj`: Added project reference to Utilities\n- `src/Build/Evaluation/Expander/WellKnownFunctions.cs`: Added fast-path implementations\n- `src/Build.UnitTests/Evaluation/Expander_Tests.cs`: Added test case\n\n## Testing\n- âœ… Successfully built entire solution\n- âœ… Added and verified test case `TestToolLocationHelperFastPaths` \n- âœ… Verified existing ToolLocationHelper tests still pass\n- âœ… Confirmed fast-paths execute without errors and return expected results\n\nFixes #12024.\n\n> [!WARNING]\n>\n> <details>\n> <summary>Firewall rules blocked me from connecting to one or more addresses</summary>\n>\n> #### I tried to connect to the following addresses, but was blocked by firewall rules:\n>\n> - `dnceng.pkgs.visualstudio.com`\n>   - Triggering command: `dotnet build src/Build/Microsoft.Build.csproj --configuration Debug --verbosity minimal ` (dns block)\n>   - Triggering command: `dotnet test src/Build.UnitTests/Microsoft.Build.Engine.UnitTests.csproj --filter TestToolLocationHelperFastPaths --configuration Debug --verbosity normal ` (dns block)\n>   - Triggering command: `/home/REDACTED/work/_temp/ghcca-node/node/bin/node /home/REDACTED/work/_temp/copilot-developer-action-main/dist/index.js ` (dns block)\n>\n> If you need me to access, download, or install something from one of these locations, you can either:\n>\n> - Configure [Actions setup steps](https://gh.io/copilot/actions-setup-steps) to set up my environment, which run before the firewall is enabled\n> - Add the appropriate URLs or hosts to my [firewall allow list](https://gh.io/copilot/firewall-config)\n>\n> </details>\n\n\n\n<!-- START COPILOT CODING AGENT TIPS -->\n---\n\nðŸ’¬ Share your feedback on Copilot coding agent for the chance to win a $200 gift card! Click [here](https://survey.alchemer.com/s3/8343779/Copilot-Coding-agent) to start the survey.",
         "Copilot"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>body</th>\n",
       "      <th>agent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7854</td>\n",
       "      <td>perf</td>\n",
       "      <td>Improve Rust compiler output</td>\n",
       "      <td>## Summary\\n- tweak Rust compiler to print sim...</td>\n",
       "      <td>OpenAI_Codex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>856</td>\n",
       "      <td>perf</td>\n",
       "      <td>perf(web): use route matcher in edge middleware</td>\n",
       "      <td>Use Next.js `matcher` in edge middleware to op...</td>\n",
       "      <td>Cursor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2463</td>\n",
       "      <td>perf</td>\n",
       "      <td>Improve Java compiler runtime emission</td>\n",
       "      <td>## Summary\\n- only emit Java runtime helpers w...</td>\n",
       "      <td>OpenAI_Codex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>perf</td>\n",
       "      <td>Improve TTI provider reliability</td>\n",
       "      <td>## Summary\\n- verify proxies when fetching fro...</td>\n",
       "      <td>OpenAI_Codex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12025</td>\n",
       "      <td>perf</td>\n",
       "      <td>Add fast-paths for ToolLocationHelper property...</td>\n",
       "      <td>This PR adds fast-path implementations for two...</td>\n",
       "      <td>Copilot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   number  type                                              title  \\\n",
       "0    7854  perf                       Improve Rust compiler output   \n",
       "1     856  perf    perf(web): use route matcher in edge middleware   \n",
       "2    2463  perf             Improve Java compiler runtime emission   \n",
       "3      70  perf                   Improve TTI provider reliability   \n",
       "4   12025  perf  Add fast-paths for ToolLocationHelper property...   \n",
       "\n",
       "                                                body         agent  \n",
       "0  ## Summary\\n- tweak Rust compiler to print sim...  OpenAI_Codex  \n",
       "1  Use Next.js `matcher` in edge middleware to op...        Cursor  \n",
       "2  ## Summary\\n- only emit Java runtime helpers w...  OpenAI_Codex  \n",
       "3  ## Summary\\n- verify proxies when fetching fro...  OpenAI_Codex  \n",
       "4  This PR adds fast-path implementations for two...       Copilot  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"prswithtasks.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc36a20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your output should be one of: 'runtime', or 'energy'.\n"
     ]
    }
   ],
   "source": [
    "class PerformanceClassifierParser(BaseOutputParser):\n",
    "    \"\"\"\n",
    "    Parses the output of an LLM call to classify a pull request.\n",
    "    The expected output is 'runtime', 'energy',.\n",
    "    \"\"\"\n",
    "\n",
    "    def parse(self, text: str) -> str:\n",
    "        \"\"\"\n",
    "        Parses the text output from the language model.\n",
    "\n",
    "        Args:\n",
    "            text: The text output from the language model.\n",
    "\n",
    "        Returns:\n",
    "            The parsed classification ('runtime', 'energy'').\n",
    "        \"\"\"\n",
    "        cleaned_text = text.strip().lower()\n",
    "        if cleaned_text in [\"runtime\", \"energy\"]:\n",
    "            return cleaned_text\n",
    "    \n",
    "\n",
    "    def get_format_instructions(self) -> str:\n",
    "        \"\"\"Instructions on how the LLM should format its response.\"\"\"\n",
    "        return \"Your output should be one of: 'runtime', or 'energy'.\"\n",
    "\n",
    "parser = PerformanceClassifierParser()\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d757a104",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'gemini-2.5-flash'\n",
    "llm = ChatGoogleGenerativeAI(model=model_name, google_api_key=os.getenv('GOOGLE_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4fd135ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"user\", user_prompt),\n",
    "])\n",
    "\n",
    "parser = PerformanceClassifierParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa15d538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your output should be one of: 'runtime', or 'energy'. It should not be None!\n"
     ]
    }
   ],
   "source": [
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d0b32e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = classification_prompt_template | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca6df40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25720bf2",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      3\u001b[39m body = row[\u001b[33m'\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m      5\u001b[39m input_vars = {\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mformat_instructions\u001b[39m\u001b[33m\"\u001b[39m: parser.get_format_instructions(),\n\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m\"\u001b[39m: title,\n\u001b[32m      8\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m\"\u001b[39m: body,\n\u001b[32m      9\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m classification = \u001b[43mchain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m classified_df.at[idx, \u001b[33m\"\u001b[39m\u001b[33mclassification\u001b[39m\u001b[33m\"\u001b[39m] = classification\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mClassification: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclassification\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/aise/lib/python3.13/site-packages/langchain_core/runnables/base.py:3245\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3243\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3244\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3245\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3246\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3247\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/aise/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:395\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    390\u001b[39m     **kwargs: Any,\n\u001b[32m    391\u001b[39m ) -> BaseMessage:\n\u001b[32m    392\u001b[39m     config = ensure_config(config)\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    394\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    405\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/aise/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1023\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1014\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1020\u001b[39m     **kwargs: Any,\n\u001b[32m   1021\u001b[39m ) -> LLMResult:\n\u001b[32m   1022\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/aise/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:840\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    838\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    839\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m840\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    846\u001b[39m         )\n\u001b[32m    847\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    848\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/aise/lib/python3.13/site-packages/langchain_core/language_models/chat_models.py:1089\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1087\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1088\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1089\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1093\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/aise/lib/python3.13/site-packages/langchain_community/chat_models/ollama.py:291\u001b[39m, in \u001b[36mChatOllama._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m    268\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    269\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    272\u001b[39m     **kwargs: Any,\n\u001b[32m    273\u001b[39m ) -> ChatResult:\n\u001b[32m    274\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Call out to Ollama's generate endpoint.\u001b[39;00m\n\u001b[32m    275\u001b[39m \n\u001b[32m    276\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    288\u001b[39m \u001b[33;03m            ])\u001b[39;00m\n\u001b[32m    289\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m     final_chunk = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_chat_stream_with_aggregation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m     chat_generation = ChatGeneration(\n\u001b[32m    299\u001b[39m         message=AIMessage(content=final_chunk.text),\n\u001b[32m    300\u001b[39m         generation_info=final_chunk.generation_info,\n\u001b[32m    301\u001b[39m     )\n\u001b[32m    302\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatResult(generations=[chat_generation])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/aise/lib/python3.13/site-packages/langchain_community/chat_models/ollama.py:222\u001b[39m, in \u001b[36mChatOllama._chat_stream_with_aggregation\u001b[39m\u001b[34m(self, messages, stop, run_manager, verbose, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_stream_with_aggregation\u001b[39m(\n\u001b[32m    214\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    215\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m    219\u001b[39m     **kwargs: Any,\n\u001b[32m    220\u001b[39m ) -> ChatGenerationChunk:\n\u001b[32m    221\u001b[39m     final_chunk: Optional[ChatGenerationChunk] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_chat_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m            \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_chat_stream_response_to_chat_generation_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstream_resp\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/aise/lib/python3.13/site-packages/langchain_community/chat_models/ollama.py:194\u001b[39m, in \u001b[36mChatOllama._create_chat_stream\u001b[39m\u001b[34m(self, messages, stop, **kwargs)\u001b[39m\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_create_chat_stream\u001b[39m(\n\u001b[32m    185\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    186\u001b[39m     messages: List[BaseMessage],\n\u001b[32m    187\u001b[39m     stop: Optional[List[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    188\u001b[39m     **kwargs: Any,\n\u001b[32m    189\u001b[39m ) -> Iterator[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    190\u001b[39m     payload = {\n\u001b[32m    191\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m.model,\n\u001b[32m    192\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m._convert_messages_to_ollama_messages(messages),\n\u001b[32m    193\u001b[39m     }\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_stream(\n\u001b[32m    195\u001b[39m         payload=payload, stop=stop, api_url=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.base_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/api/chat\u001b[39m\u001b[33m\"\u001b[39m, **kwargs\n\u001b[32m    196\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/aise/lib/python3.13/site-packages/requests/models.py:869\u001b[39m, in \u001b[36mResponse.iter_lines\u001b[39m\u001b[34m(self, chunk_size, decode_unicode, delimiter)\u001b[39m\n\u001b[32m    860\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Iterates over the response data, one line at a time.  When\u001b[39;00m\n\u001b[32m    861\u001b[39m \u001b[33;03mstream=True is set on the request, this avoids reading the\u001b[39;00m\n\u001b[32m    862\u001b[39m \u001b[33;03mcontent at once into memory for large responses.\u001b[39;00m\n\u001b[32m    863\u001b[39m \n\u001b[32m    864\u001b[39m \u001b[33;03m.. note:: This method is not reentrant safe.\u001b[39;00m\n\u001b[32m    865\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    867\u001b[39m pending = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m869\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_unicode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_unicode\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpending\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m:\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mpending\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/aise/lib/python3.13/site-packages/requests/utils.py:562\u001b[39m, in \u001b[36mstream_decode_response_unicode\u001b[39m\u001b[34m(iterator, r)\u001b[39m\n\u001b[32m    559\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m    561\u001b[39m decoder = codecs.getincrementaldecoder(r.encoding)(errors=\u001b[33m\"\u001b[39m\u001b[33mreplace\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m562\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    563\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrv\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    564\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrv\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/aise/lib/python3.13/site-packages/requests/models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/aise/lib/python3.13/site-packages/urllib3/response.py:1088\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1072\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1073\u001b[39m \u001b[33;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[32m   1074\u001b[39m \u001b[33;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1085\u001b[39m \u001b[33;03m    'content-encoding' header.\u001b[39;00m\n\u001b[32m   1086\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1087\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.supports_chunked_reads():\n\u001b[32m-> \u001b[39m\u001b[32m1088\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.read_chunked(amt, decode_content=decode_content)\n\u001b[32m   1089\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1090\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/aise/lib/python3.13/site-packages/urllib3/response.py:1248\u001b[39m, in \u001b[36mHTTPResponse.read_chunked\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1245\u001b[39m     amt = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1247\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1248\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1249\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunk_left == \u001b[32m0\u001b[39m:\n\u001b[32m   1250\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/aise/lib/python3.13/site-packages/urllib3/response.py:1167\u001b[39m, in \u001b[36mHTTPResponse._update_chunk_length\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1166\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1167\u001b[39m line = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m   1168\u001b[39m line = line.split(\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m;\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m   1169\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Caskroom/miniforge/base/envs/aise/lib/python3.13/socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for idx, row in classified_df.iterrows():\n",
    "    title = row['title']\n",
    "    body = row['body']\n",
    "\n",
    "    input_vars = {\n",
    "        \"format_instructions\": parser.get_format_instructions(),\n",
    "        \"title\": title,\n",
    "        \"body\": body,\n",
    "    }\n",
    "    \n",
    "    classification = chain.invoke(input_vars)\n",
    "    classified_df.at[idx, \"classification\"] = classification\n",
    "    \n",
    "    print(f\"Classification: {classification}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a864d9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_df.to_csv(\"classified_prs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6ee83c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "classified_df = pd.read_csv(\"classified_prs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00d708f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification\n",
      "runtime    331\n",
      "energy       7\n",
      "NaN          2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "classification_counts = classified_df['classification'].value_counts(dropna=False)\n",
    "print(classification_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b4c3371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14] | Title: [WIP] Request to reduce SQL query count for homepage posts.\n",
      "Row 14 classified as: None\n",
      "[44] | Title: Replace Math.DivRem with bit operations in BitArray for WASM performance\n",
      "Row 44 classified as: None\n"
     ]
    }
   ],
   "source": [
    "nan_rows = classified_df[classified_df['classification'].isna()]\n",
    "\n",
    "for idx, row in nan_rows.iterrows():\n",
    "    title = row['title']\n",
    "    body = row['body']\n",
    "\n",
    "    input_vars = {\n",
    "        \"format_instructions\": parser.get_format_instructions(),\n",
    "        \"title\": title,\n",
    "        \"body\": body,\n",
    "    }\n",
    "    print(f\"[{idx}] | Title: {title}\")\n",
    "    classification = chain.invoke(input_vars)\n",
    "    classified_df.at[idx, \"classification\"] = classification\n",
    "    print(f\"Row {idx} classified as: {classification}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
